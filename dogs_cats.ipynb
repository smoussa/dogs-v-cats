{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data and organise into folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir data/images\n",
    "mkdir data/models\n",
    "mkdir data/predictions\n",
    "\n",
    "cd data\n",
    "unzip test.zip -d images\n",
    "unzip train.zip -d images\n",
    "\n",
    "cd images\n",
    "mkdir valid\n",
    "mkdir valid/cats\n",
    "mkdir valid/dogs\n",
    "mkdir train/cats\n",
    "mkdir train/dogs\n",
    "mkdir test/unknown\n",
    "\n",
    "mkdir sample\n",
    "mkdir sample/train\n",
    "mkdir sample/test\n",
    "mkdir sample/valid\n",
    "mkdir sample/train/cats\n",
    "mkdir sample/train/dogs\n",
    "mkdir sample/valid/cats\n",
    "mkdir sample/valid/dogs\n",
    "mkdir sample/test/unknown\n",
    "\n",
    "ls train | grep cat. | xargs -I {} mv train/{} train/cats\n",
    "ls train | grep dog. | xargs -I {} mv train/{} train/dogs\n",
    "ls test | xargs -I {} mv test/{} test/unknown\n",
    "\n",
    "cd train\n",
    "ls cats | tail -1000 | xargs -I {} mv cats/{} ../valid/cats\n",
    "ls dogs | tail -1000 | xargs -I {} mv dogs/{} ../valid/dogs\n",
    "ls cats | tail -50 | xargs -I {} cp cats/{} ../sample/train/cats\n",
    "ls dogs | tail -50 | xargs -I {} cp dogs/{} ../sample/train/dogs\n",
    "\n",
    "cd ../valid\n",
    "ls cats | tail -10 | xargs -I {} cp cats/{} ../sample/valid/cats\n",
    "ls dogs | tail -10 | xargs -I {} cp dogs/{} ../sample/valid/dogs\n",
    "\n",
    "cd ../test\n",
    "ls unknown | tail -10 | xargs -I {} cp unknown/{} ../sample/test/unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data/\n",
    "    sample/\n",
    "        train/\n",
    "            cats/\n",
    "            dogs/\n",
    "        valid/\n",
    "            dogs/\n",
    "            cats/\n",
    "        test/\n",
    "            cats/\n",
    "            dogs/\n",
    "    train/\n",
    "        cats/\n",
    "        dogs/\n",
    "    valid/\n",
    "        cats/\n",
    "        dogs/\n",
    "    test/\n",
    "        unknown/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, ujson\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import bcolz\n",
    "import itertools\n",
    "from IPython.display import FileLink\n",
    "\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.preprocessing import image\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4, linewidth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design VGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg_image_rgb_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n",
    "def vgg_preprocess(x):\n",
    "    x -= vgg_image_rgb_mean\n",
    "    return x[:, ::-1] # reverse axis: rgb -> bgr\n",
    "\n",
    "def ConvBlock(model, n_layers, n_filters):\n",
    "    for i in range(n_layers):\n",
    "        model.add(ZeroPadding2D((1, 1))) # add zero padding around image\n",
    "        model.add(Convolution2D(n_filters, 3, 3, activation='relu')) # 3x3 convolutions with n_filters\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "def FCBlock(model):\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "class Vgg16():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vgg_url_prefix = 'http://www.platform.ai/models/'\n",
    "        self.create()\n",
    "        self.get_classes()\n",
    "    \n",
    "    def create(self):\n",
    "        model = Sequential()\n",
    "        model.add(Lambda(vgg_preprocess, input_shape=(3, 224, 224))) # (rgb, width, height)\n",
    "        ConvBlock(model, 2, 64)\n",
    "        ConvBlock(model, 2, 128)\n",
    "        ConvBlock(model, 3, 256)\n",
    "        ConvBlock(model, 3, 512)\n",
    "        ConvBlock(model, 3, 512)\n",
    "        model.add(Flatten()) # flattens tensor without affecting first dimension (batch size)\n",
    "        FCBlock(model)\n",
    "        FCBlock(model)\n",
    "        model.add(Dense(1000, activation='softmax'))\n",
    "        \n",
    "        # download and assign pretrained weights to model\n",
    "        fname = 'vgg16.h5'\n",
    "        model.load_weights(get_file(fname, self.vgg_url_prefix + fname, cache_subdir='models'))\n",
    "        self.model = model\n",
    "    \n",
    "    def get_classes(self):\n",
    "        fname = 'imagenet_class_index.json'\n",
    "        fpath = get_file(fname, self.vgg_url_prefix + fname, cache_subdir='models')\n",
    "        with open(fpath) as f:\n",
    "            class_dict = ujson.load(f)\n",
    "        # class_dict has value: [{\"0\": [\"n01440764\", \"tench\"], \"1\": [\"n01443537\", \"goldfish\"], ...]\n",
    "        self.classes = [class_dict[str(i)][1] for i in range(len(class_dict))]\n",
    "    \n",
    "    def finetune(self, n_classes):\n",
    "        self.model.pop() # remove last layer\n",
    "        for layer in self.model.layers:\n",
    "            layer.trainable = False # set all layers as non-trainable\n",
    "        self.model.add(Dense(n_classes, activation='softmax')) # add a dense layer with n_classes output\n",
    "        self.compile()\n",
    "    \n",
    "    def compile(self, lr=0.001):\n",
    "        self.model.compile(\n",
    "            optimizer=Adam(lr=lr),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "    \n",
    "    def fit_gen(self, train_batches, valid_batches, n_epochs=1):\n",
    "        self.model.fit_generator(\n",
    "            train_batches,\n",
    "            samples_per_epoch=train_batches.nb_sample,\n",
    "            validation_data=valid_batches,\n",
    "            nb_val_samples=valid_batches.nb_sample,\n",
    "            nb_epoch=n_epochs)\n",
    "    \n",
    "    def test_gen(self, test_batches):\n",
    "        return self.model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialise model\n",
    "vgg = Vgg16()\n",
    "vgg.finetune(2) # finetune model to output only two classes\n",
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_path = \"data/images/\"\n",
    "batch_size = 64\n",
    "n_epochs = 5\n",
    "model_name = 'batchnorm'\n",
    "\n",
    "def save_array(arr, fname):\n",
    "    c = bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "    \n",
    "def get_batches(path, shuffle=True, batch_size=8, class_mode='categorical'):\n",
    "    gen = image.ImageDataGenerator()\n",
    "    return gen.flow_from_directory(\n",
    "        path,\n",
    "        target_size=(224, 224),\n",
    "        class_mode=class_mode,\n",
    "        shuffle=shuffle,\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get training and validation batches (generator)\n",
    "train_batches = get_batches(images_path + 'train', batch_size=batch_size)\n",
    "valid_batches = get_batches(images_path + 'valid', batch_size=batch_size)\n",
    "test_batches = get_batches(images_path + 'test', shuffle=False, batch_size=batch_size, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train and save weights per epoch\n",
    "for i in range(n_epochs):\n",
    "    print('Running epoch: %d ...' % i)\n",
    "    vgg.fit_gen(train_batches, valid_batches, n_epochs=1)\n",
    "    vgg.model.save_weights('data/models/%s_%d.h5' % (model_name, i))\n",
    "print('Completed %d training epochs' % n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use saved weights instead of training\n",
    "vgg.model.load_weights('data/models/full_5_epochs_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = vgg.test_gen(test_batches)\n",
    "save_array(predictions, 'data/predictions/%s_test_predictions.dat' % model_name)\n",
    "save_array(test_batches.filenames, 'data/predictions/%s_test_filenames.dat' % model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions # [cat, dog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show a test image\n",
    "print(test_batches.filenames[0])\n",
    "Image.open(images_path + 'test/' + test_batches.filenames[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Validation Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict on some validation data\n",
    "predictions = vgg.test_gen(valid_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get true and predicted classes (0=cat, 1=dog)\n",
    "true_classes = valid_batches.classes\n",
    "pred_probs = predictions[:,1]\n",
    "pred_classes = np.round(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=18)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1. A few correct labels at random\n",
    "correct_indexes = np.where(pred_classes==true_classes)[0]\n",
    "print(\"Found %d correct labels\" % len(correct_indexes))\n",
    "idx = np.random.permutation(correct_indexes)[:4] # show first 4\n",
    "plots([image.load_img(images_path + 'valid/' + valid_batches.filenames[i]) for i in idx], titles=pred_probs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2. A few incorrect labels at random\n",
    "incorrect_indexes = np.where(pred_classes!=true_classes)[0]\n",
    "print(\"Found %d incorrect labels\" % len(incorrect_indexes))\n",
    "idx = np.random.permutation(incorrect_indexes)[:4] # show first 4\n",
    "plots([image.load_img(images_path + 'valid/' + valid_batches.filenames[i]) for i in idx], titles=pred_probs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3a. The images we are most confident are cats, and actually are cats\n",
    "correct_cats = np.where((pred_classes==0) & (pred_classes==true_classes))[0]\n",
    "print(\"Found %d confident correct cats\" % len(correct_cats))\n",
    "most_correct_cats = np.argsort(pred_probs[correct_cats])[::-1][:4] # sort by most confident then show first 4\n",
    "plots([image.load_img(images_path + 'valid/' + valid_batches.filenames[i]) for i in correct_cats[most_correct_cats]],\n",
    "      titles=pred_probs[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3b. The images we are most confident are dogs, and actually are dogs\n",
    "correct_dogs = np.where((pred_classes==1) & (pred_classes==true_classes))[0]\n",
    "print(\"Found %d confident correct dogs\" % len(correct_dogs))\n",
    "most_correct_dogs = np.argsort(pred_probs[correct_dogs])[::-1][:4] # sort by most confident then show first 4\n",
    "plots([image.load_img(images_path + 'valid/' + valid_batches.filenames[i]) for i in correct_dogs[most_correct_dogs]],\n",
    "      titles=pred_probs[correct_dogs][most_correct_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4a. The images we were most confident were cats, but are actually dogs\n",
    "incorrect_cats = np.where((pred_classes==0) & (pred_classes!=true_classes))[0]\n",
    "print(\"Found %d incorrect cats\" % len(incorrect_cats))\n",
    "most_incorrect_cats = np.argsort(pred_probs[incorrect_cats])[::-1][:4] # sort by most confident then show first 4\n",
    "plots([image.load_img(images_path + 'valid/' + valid_batches.filenames[i]) for i in incorrect_cats[most_incorrect_cats]],\n",
    "      titles=pred_probs[incorrect_cats][most_incorrect_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4b. The images we were most confident were dogs, but are actually cats\n",
    "incorrect_dogs = np.where((pred_classes==1) & (pred_classes!=true_classes))[0]\n",
    "print(\"Found %d incorrect dogs\" % len(incorrect_dogs))\n",
    "most_incorrect_dogs = np.argsort(pred_probs[incorrect_dogs])[::-1][:4] # sort by most confident then show first 4\n",
    "plots([image.load_img(images_path + 'valid/' + valid_batches.filenames[i]) for i in incorrect_dogs[most_incorrect_dogs]],\n",
    "      titles=pred_probs[incorrect_dogs][most_incorrect_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "idx = np.argsort(np.abs(pred_probs - 0.5))[:4]\n",
    "plots([image.load_img(images_path + 'valid/' + valid_batches.filenames[i]) for i in idx], titles=pred_probs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "cm = confusion_matrix(true_classes, pred_classes)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Dogs vs Cats: Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(valid_batches.class_indices))\n",
    "plt.xticks(tick_marks, valid_batches.class_indices, rotation=45)\n",
    "plt.yticks(tick_marks, valid_batches.class_indices)\n",
    "\n",
    "normalize = False\n",
    "if normalize:\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm)\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit predictions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission format:\n",
    "```\n",
    "imageId, isDog\n",
    "1242, .3984\n",
    "3947, .1000\n",
    "4539, .9082\n",
    "2345, .0000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load our test predictions from file\n",
    "predictions = load_array('data/predictions/%s_test_predictions.dat' % model_name)\n",
    "filenames = load_array('data/predictions/%s_test_filenames.dat' % model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clip very low or very high values\n",
    "is_dog = predictions[:,1].clip(min=0.05, max=0.95)\n",
    "\n",
    "# extract image ids from filenames\n",
    "image_ids = np.array([f.split('/')[-1][:-4] for f in filenames], dtype=np.uint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a save submission file\n",
    "submission_fname = 'data/%s_submission.csv' % model_name\n",
    "submission = np.stack((image_ids, is_dog), axis=1)\n",
    "np.savetxt(submission_fname, submission, fmt='%d,%.5f', header='id,label', comments='')\n",
    "\n",
    "# create a file link of the submission file to download and submit to Kaggle\n",
    "FileLink(submission_fname)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
